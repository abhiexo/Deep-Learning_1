{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "np.random.seed(12345)\n",
    "#%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Downlaod and load the data\n",
    "batch_size = 512\n",
    "\n",
    "train_images_path = keras.utils.get_file('train-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz')\n",
    "train_labels_path = keras.utils.get_file('train-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz')\n",
    "test_images_path = keras.utils.get_file('t10k-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = keras.utils.get_file('t10k-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(images_path, labels_path):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, y_train_orig = load_mnist(train_images_path, train_labels_path)\n",
    "X_test, y_test = load_mnist(test_images_path, test_labels_path)\n",
    "X_train_orig = X_train_orig.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_orig /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(X_train[1, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, input_shape=(784,), activation='relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 468,874\n",
      "Trainable params: 468,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.6293 - acc: 0.7814 - val_loss: 0.4188 - val_acc: 0.8580\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.4135 - acc: 0.8555 - val_loss: 0.3938 - val_acc: 0.8655\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.3788 - acc: 0.8645 - val_loss: 0.3578 - val_acc: 0.8775\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.3391 - acc: 0.8788 - val_loss: 0.3257 - val_acc: 0.8878\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.3192 - acc: 0.8852 - val_loss: 0.3165 - val_acc: 0.8878\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2998 - acc: 0.8923 - val_loss: 0.3245 - val_acc: 0.8846\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2870 - acc: 0.8946 - val_loss: 0.3136 - val_acc: 0.8896\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2745 - acc: 0.8996 - val_loss: 0.2918 - val_acc: 0.8983\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2631 - acc: 0.9032 - val_loss: 0.3005 - val_acc: 0.8929\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2499 - acc: 0.9076 - val_loss: 0.2861 - val_acc: 0.9003\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2429 - acc: 0.9093 - val_loss: 0.2904 - val_acc: 0.8949\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2319 - acc: 0.9136 - val_loss: 0.2993 - val_acc: 0.8946\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2265 - acc: 0.9165 - val_loss: 0.2859 - val_acc: 0.8963\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2165 - acc: 0.9203 - val_loss: 0.3007 - val_acc: 0.8957\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2018 - acc: 0.9265 - val_loss: 0.2771 - val_acc: 0.9032\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.1993 - acc: 0.9263 - val_loss: 0.2826 - val_acc: 0.9017\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.1894 - acc: 0.9301 - val_loss: 0.2949 - val_acc: 0.8982\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.1863 - acc: 0.9304 - val_loss: 0.2919 - val_acc: 0.8986\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.1817 - acc: 0.9323 - val_loss: 0.2783 - val_acc: 0.9037\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.1693 - acc: 0.9376 - val_loss: 0.2924 - val_acc: 0.9019\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.35090857729911806\n",
      "Test accuracy: 0.8815\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
